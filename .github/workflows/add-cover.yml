name: Add Cover Image from Webhook

on:
  repository_dispatch:
    types: [add_cover_image]
  workflow_dispatch:
    inputs:
      file_path:
        description: "MDX file path (e.g. content/blog/my-slug.mdx)"
        required: true
        type: string
      image_url:
        description: "Cover image URL"
        required: true
        type: string
      cover_alt:
        description: "Alt text for the cover image"
        required: true
        type: string

permissions:
  contents: write

jobs:
  add-cover:
    runs-on: ubuntu-latest
    concurrency:
      group: add-cover-image-${{ github.event.client_payload.file_path || github.event.inputs.file_path || github.run_id }}
      cancel-in-progress: false
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Normalize metadata before cover update
        run: node scripts/fix-missing-metadata.js

      - name: Add cover image to MDX metadata (commit & push)
        id: add_cover
        run: |
          set -euo pipefail

          python3 - <<'PY'
          import json
          import os
          import re

          event_path = os.environ.get("GITHUB_EVENT_PATH")
          if not event_path:
            raise SystemExit("❌ Missing GITHUB_EVENT_PATH")

          with open(event_path, "r", encoding="utf-8") as f:
            event = json.load(f)

          inputs = event.get("inputs") or {}
          payload = event.get("client_payload") or {}

          file_path = (inputs.get("file_path") or payload.get("file_path") or "").strip()
          url = (inputs.get("image_url") or payload.get("image_url") or "").strip()
          alt = (inputs.get("cover_alt") or payload.get("cover_alt") or "").strip()

          if not file_path or not url or not alt:
            raise SystemExit("❌ Missing payload. Expecting file_path, image_url, cover_alt")

          if not re.match(r"^content/blog/[^/]+\.mdx$", file_path):
            raise SystemExit(f"❌ Refusing to edit unexpected path: {file_path}")

          if not os.path.isfile(file_path):
            raise SystemExit(f"❌ File not found: {file_path}")

          slug = file_path.removeprefix("content/blog/").removesuffix(".mdx")
          print(f"ℹ️  Target file: {file_path}")
          print(f"ℹ️  Slug: {slug}")
          print(f"ℹ️  Image URL: {url}")

          with open(file_path, "r", encoding="utf-8") as f:
            src = f.read()

          start_re = re.compile(r"export\s+const\s+metadata\s*=\s*\{")
          m = start_re.search(src)
          if not m:
            raise SystemExit(f"No `export const metadata = {{` block found in {file_path}")

          brace_start = m.end() - 1  # index at '{'
          brace_count = 0
          in_str = False
          str_ch = ""
          escape = False
          end_idx = -1

          for i in range(brace_start, len(src)):
            ch = src[i]
            if in_str:
              if escape:
                escape = False
                continue
              if ch == "\\":
                escape = True
                continue
              if ch == str_ch:
                in_str = False
                str_ch = ""
              continue
            else:
              if ch in ('"', "'"):
                in_str = True
                str_ch = ch
                continue
              if ch == "{":
                brace_count += 1
              elif ch == "}":
                brace_count -= 1
                if brace_count == 0:
                  end_idx = i
                  break

          if end_idx == -1:
            raise SystemExit(f"Could not find end of metadata object in {file_path}")

          meta_obj = src[brace_start : end_idx + 1]
          meta_lines = meta_obj.splitlines(True)

          title_line_idx = None
          insert_idx = None
          title_line_re = re.compile(r"^(\s*)title\s*:\s*([\"']).*\2\s*,?\s*$")
          indent = "  "
          for idx, line in enumerate(meta_lines):
            mm = title_line_re.match(line)
            if mm:
              title_line_idx = idx
              indent = mm.group(1)
              insert_idx = idx + 1
              break

          if insert_idx is None:
            prop_re = re.compile(r"^(\s*)[A-Za-z_][A-Za-z0-9_]*\s*:")
            for idx, line in enumerate(meta_lines):
              mm = prop_re.match(line)
              if mm:
                indent = mm.group(1)
                insert_idx = idx + 1
                break

          if insert_idx is None:
            # Insert before closing brace if object is empty or unusual formatting.
            insert_idx = max(1, len(meta_lines) - 1)

          def make_field_line(key: str, value: str) -> str:
            return f"{indent}{key}: {json.dumps(value)},\n"

          def upsert_field(key: str, value: str):
            field_re = re.compile(rf"^(\s*){re.escape(key)}\s*:\s*")
            for i, line in enumerate(meta_lines):
              if field_re.match(line):
                meta_lines[i] = make_field_line(key, value)
                return
            meta_lines.insert(insert_idx, make_field_line(key, value))

          upsert_field("coverImage", url)
          upsert_field("coverAlt", alt)

          new_meta_obj = "".join(meta_lines)
          out = src[:brace_start] + new_meta_obj + src[end_idx + 1 :]

          with open(file_path, "w", encoding="utf-8") as f:
            f.write(out)

          github_output = os.environ.get("GITHUB_OUTPUT")
          if github_output:
            with open(github_output, "a", encoding="utf-8") as f:
              f.write(f"file_path={file_path}\n")
              f.write(f"slug={slug}\n")

          print(f"✅ Updated coverImage/coverAlt in {file_path}")
          PY

          # Keep precompiled blog JSON in sync (site reads from public/blog-data/*.json)
          python3 - <<'PY'
          import json
          import os
          import re

          event_path = os.environ.get("GITHUB_EVENT_PATH")
          if not event_path:
            raise SystemExit("❌ Missing GITHUB_EVENT_PATH")

          with open(event_path, "r", encoding="utf-8") as f:
            event = json.load(f)

          inputs = event.get("inputs") or {}
          payload = event.get("client_payload") or {}

          file_path = (inputs.get("file_path") or payload.get("file_path") or "").strip()
          url = (inputs.get("image_url") or payload.get("image_url") or "").strip()
          alt = (inputs.get("cover_alt") or payload.get("cover_alt") or "").strip()

          if not file_path or not url or not alt:
            raise SystemExit("❌ Missing payload. Expecting file_path, image_url, cover_alt")

          if not re.match(r"^content/blog/[^/]+\.mdx$", file_path):
            raise SystemExit(f"❌ Refusing to edit unexpected path: {file_path}")

          slug = file_path.removeprefix("content/blog/").removesuffix(".mdx")
          json_path = os.path.join("public", "blog-data", f"{slug}.json")

          if not os.path.isfile(json_path):
            print(f"ℹ️  JSON not found (skipping): {json_path}")
            raise SystemExit(0)

          with open(json_path, "r", encoding="utf-8") as f:
            data = json.load(f)

          data.setdefault("metadata", {})
          data["metadata"]["coverImage"] = url
          data["metadata"]["coverAlt"] = alt

          tm = data.get("translatedMetadata")
          if isinstance(tm, dict) and isinstance(tm.get("fr"), dict):
            tm["fr"]["coverImage"] = url
            # Prefer keeping an existing translated coverAlt if present
            if not tm["fr"].get("coverAlt"):
              tm["fr"]["coverAlt"] = alt

          with open(json_path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
            f.write("\n")

          print(f"✅ Updated coverImage/coverAlt in {json_path}")
          PY

          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          FILE_PATH=$(python3 -c "import json,os; d=json.load(open(os.environ['GITHUB_EVENT_PATH'])); i=d.get('inputs') or {}; p=d.get('client_payload') or {}; print((i.get('file_path') or p.get('file_path') or '').strip())")
          if [ -z "${FILE_PATH:-}" ]; then
            echo "❌ Missing file_path in event payload"
            exit 1
          fi

          echo "ℹ️  Staging: ${FILE_PATH}"
          git add "${FILE_PATH}"

          if ! grep -q "coverImage:" "${FILE_PATH}" || ! grep -q "coverAlt:" "${FILE_PATH}"; then
            echo "❌ coverImage/coverAlt still missing after update: ${FILE_PATH}"
            exit 1
          fi

          SLUG=$(python3 -c "import json,os; d=json.load(open(os.environ['GITHUB_EVENT_PATH'])); i=d.get('inputs') or {}; p=d.get('client_payload') or {}; fp=(i.get('file_path') or p.get('file_path') or '').strip(); print(fp.replace('content/blog/','').replace('.mdx',''))")
          if [ -n "${SLUG:-}" ] && [ -f "public/blog-data/${SLUG}.json" ]; then
            echo "ℹ️  Staging: public/blog-data/${SLUG}.json"
            git add "public/blog-data/${SLUG}.json"
          fi

          if git diff --cached --quiet; then
            echo "✅ No changes to commit"
            exit 0
          fi

          git commit -m "✨ Add cover image to article"

          # Prevent occasional non-fast-forward failures when multiple dispatches land close together.
          # We serialize runs via `concurrency`, but still rebase+retry defensively.
          BRANCH="${GITHUB_REF_NAME:-main}"
          echo "ℹ️  Syncing with origin/${BRANCH} before push"
          git stash || true
          git pull --rebase origin "${BRANCH}" || true
          git stash pop || true

          for attempt in 1 2 3; do
            echo "ℹ️  Push attempt ${attempt}/3"
            if git push origin "HEAD:${BRANCH}"; then
              echo "✅ Pushed successfully"
              break
            fi

            if [ "${attempt}" -eq 3 ]; then
              echo "❌ Push failed after 3 attempts (likely concurrent updates to the same file)."
              exit 1
            fi

            echo "⚠️  Push failed; rebasing and retrying..."
            git stash || true
            git pull --rebase origin "${BRANCH}"
            git stash pop || true
          done

      - name: Revalidate site cache (optional)
        continue-on-error: true
        env:
          SITE_URL: ${{ secrets.SITE_URL || 'https://skynet-consulting.net' }}
          REVALIDATE_SECRET: ${{ secrets.REVALIDATE_SECRET }}
          SLUG: ${{ steps.add_cover.outputs.slug }}
        run: |
          set -euo pipefail

          if [ -z "${REVALIDATE_SECRET:-}" ]; then
            echo "ℹ️  No REVALIDATE_SECRET set; skipping revalidate"
            exit 0
          fi

          if [ -z "${SLUG:-}" ]; then
            echo "ℹ️  No slug output; skipping revalidate"
            exit 0
          fi

          SITE_URL="${SITE_URL/https:\/\/www.skynet-consulting.net/https:\/\/skynet-consulting.net}"
          SITE_URL="${SITE_URL/http:\/\/www.skynet-consulting.net/http:\/\/skynet-consulting.net}"

          echo "ℹ️  Revalidating /blog and /blog/${SLUG}"
          http_code=$(curl -sS -L -o response.json -w "%{http_code}" \
            -X POST "${SITE_URL}/api/revalidate" \
            -H "Content-Type: application/json" \
            -H "x-revalidate-secret: ${REVALIDATE_SECRET}" \
            --data "{\"slug\":\"${SLUG}\"}")

          echo "HTTP ${http_code}"
          cat response.json || true

          if [ "${http_code}" != "200" ]; then
            echo "⚠️  Revalidate failed (non-blocking). Check REVALIDATE_SECRET in Vercel/GitHub."
            exit 0
          fi
